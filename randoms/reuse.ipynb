{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-46-bc0026aca656>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-46-bc0026aca656>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    from tensorflow.keras.utils import HDF5Matrix data=HDF5Matrix(\"data.hdf5\",\"data\")\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import vgg16\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import HDF5Matrix data=HDF5Matrix(\"data.hdf5\",\"data\")\n",
    "\n",
    "\n",
    "#loading conv layers - aka classifiers\n",
    "#btw last layer has shape 7x7x512\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "train_dir = './datasets/train'\n",
    "test_dir = './datasets/test'\n",
    "\n",
    "nTrain = 200\n",
    "nTest = 100\n",
    "batch_size=20\n",
    "\n",
    "#network output tensor shape\n",
    "train_features = np.zeros(shape=(nTrain, 7, 7, 512))\n",
    "train_labels = np.zeros(shape=(nTrain, 3))\n",
    "\n",
    "test_features = np.zeros(shape=(nTest, 7, 7, 512))\n",
    "test_labels = np.zeros(shape=(nTest, 3))\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255) #normalize the data to range from 0 to 1\n",
    "train_generator = datagen.flow_from_directory( #or hot one encoding for transforming into binary matrix, best modelling of classification problem\n",
    "    train_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "#iterate through batches\n",
    "for i, (inputs_batch, labels_batch) in enumerate(train_generator):\n",
    "    if i*batch_size >= nTrain:\n",
    "        break\n",
    "    if i*batch_size < nTest:\n",
    "        \n",
    "        features_batch = vgg_conv.predict(inputs_batch)\n",
    "        train_features[i*batch_size:(i+1)*batch_size] = features_batch\n",
    "        train_labels[i*batch_size:(i+1)*batch_size] = labels_batch\n",
    "        \n",
    "for i, (inputs_batch, labels_batch) in enumerate(test_generator):\n",
    "    if i*batch_size >= nTest:\n",
    "        break\n",
    "    if i*batch_size < nTest:\n",
    "        features_batch = vgg_conv.predict(inputs_batch)\n",
    "        test_features[i*batch_size:(i+1)*batch_size] = features_batch\n",
    "        test_labels[i*batch_size:(i+1)*batch_size] = labels_batch\n",
    "    \n",
    "train_features_vec = np.reshape(train_features, (nTrain, 7*7*512))\n",
    "test_features_vec = np.reshape(test_features, (nTest, 7*7*512))\n",
    "\n",
    "print(\"Train features: {}\".format(train_features_vec.shape))\n",
    "print(\"Test features: {}\".format(test_features_vec.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 12,847,107\n",
      "Trainable params: 12,847,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(vgg_conv)\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', input_dim=7*7*512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8400e-04 - acc: 0.5622 - val_loss: 0.2744 - val_acc: 0.9100\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 1.2365e-04 - acc: 0.5904 - val_loss: 0.2320 - val_acc: 0.9300\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 0.0016 - acc: 0.5319 - val_loss: 0.7230 - val_acc: 0.8900\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.0306 - acc: 0.5730 - val_loss: 1.3229 - val_acc: 0.8000\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.3190 - acc: 0.6097 - val_loss: 0.3540 - val_acc: 0.9200\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.4806 - acc: 0.4986 - val_loss: 0.4229 - val_acc: 0.9000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 1.0392 - acc: 0.4891 - val_loss: 1.3343 - val_acc: 0.8100\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 2.7114 - acc: 0.5772 - val_loss: 28.4855 - val_acc: 0.5600\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 7.5986 - acc: 0.3905 - val_loss: 4.1635 - val_acc: 0.5700\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 3.6934 - acc: 0.5392 - val_loss: 1.9254 - val_acc: 0.6600\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.9663 - acc: 0.5234 - val_loss: 0.9289 - val_acc: 0.8400\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 1.0755 - acc: 0.5742 - val_loss: 0.4491 - val_acc: 0.8900\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 1s 81ms/step - loss: 0.5520 - acc: 0.6015 - val_loss: 0.5868 - val_acc: 0.7600\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 0.2297 - acc: 0.5249 - val_loss: 0.4744 - val_acc: 0.8400\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3283 - acc: 0.5045 - val_loss: 0.9087 - val_acc: 0.5100\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.3122 - acc: 0.5283 - val_loss: 0.5581 - val_acc: 0.7700\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 1s 86ms/step - loss: 0.2928 - acc: 0.6080 - val_loss: 0.3129 - val_acc: 0.9000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1975 - acc: 0.5172 - val_loss: 0.3905 - val_acc: 0.8800\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.1682 - acc: 0.6501 - val_loss: 0.4828 - val_acc: 0.8400\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.3304 - acc: 0.5683 - val_loss: 0.4190 - val_acc: 0.8700\n"
     ]
    }
   ],
   "source": [
    "### TRAIN\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.01, momentum=0.9, decay=0.01/25, nesterov=False)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features_vec,\n",
    "                    train_labels,\n",
    "                    epochs=20,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(test_features_vec, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK PERFORMANCE\n",
    "\n",
    "file_names = test_generator.filenames\n",
    "ground_truth = test_generator.classes\n",
    "label2index = test_generator.class_indices\n",
    "idx2label = list(label2index.keys())\n",
    "\n",
    "print(label2index)\n",
    "print(f\"The list of classes {idx2label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts each img in the array\n",
    "# predictions = model.predict_classes(test_features_vec)\n",
    "predictions = np.argmax(model.predict(test_features_vec), axis=-1)\n",
    "print(predictions)\n",
    "\n",
    "probs = model.predict(test_features_vec)\n",
    "print(probs)\n",
    "\n",
    "err = np.where(predictions != ground_truth)[0]\n",
    "print(f\"Encountered {len(err)} error/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.00000047683716\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_features_vec, test_labels, verbose=0)\n",
    "print(\"Accuracy: {}\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(err)):\n",
    "    pred_class = np.argmax(probs[err[i]])\n",
    "    pred_label = idx2label[pred_class]\n",
    "    print(\"Original label: {}, Prediction: {}, Confidence: {}\".format(\n",
    "        file_names[err[i]].split(\"/\")[0],\n",
    "        pred_label,\n",
    "        probs[err[i]][pred_class]\n",
    "    ))\n",
    "    original = load_img('{}/{}'.format(test_dir, file_names[err[i]]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(original)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(history):\n",
    "    acc = history.history['acc']\n",
    "    test_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    test_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc, 'b', label=\"Training accuracy\")\n",
    "    plt.plot(epochs, test_acc, 'r', label=\"Test accuracy\")\n",
    "    plt.title('Training and test accuracy')\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(epochs, loss, 'b', label=\"Training loss\")\n",
    "    plt.plot(epochs, test_loss, 'r', label=\"Test loss\")\n",
    "    plt.title('Training and test loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "visualize_results(history)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for obtaining of the errors \n",
    "def obtain_errors(val_generator, predictions):\n",
    "    # Get the filenames from the generator\n",
    "    fnames = val_generator.filenames\n",
    "\n",
    "    # Get the ground truth from generator\n",
    "    ground_truth = val_generator.classes\n",
    "\n",
    "    # Get the dictionary of classes\n",
    "    label2index = val_generator.class_indices\n",
    "\n",
    "    # Obtain the list of the classes\n",
    "    idx2label = list(label2index.keys())\n",
    "    print(\"The list of classes: \", idx2label)\n",
    "\n",
    "    # Get the class index\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    errors = np.where(predicted_classes != ground_truth)[0]\n",
    "    print(\"Number of errors = {}/{}\".format(len(errors),val_generator.samples))\n",
    "    \n",
    "    return idx2label, errors, fnames\n",
    "\n",
    "\n",
    "# Utility function for visualization of the errors\n",
    "def show_errors(idx2label, errors, predictions, fnames):\n",
    "    # Show the errors\n",
    "    for i in range(len(errors)):\n",
    "        pred_class = np.argmax(predictions[errors[i]])\n",
    "        pred_label = idx2label[pred_class]\n",
    "\n",
    "        title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "            fnames[errors[i]].split('/')[0],\n",
    "            pred_label,\n",
    "            predictions[errors[i]][pred_class])\n",
    "\n",
    "        original = load_img('{}/{}'.format(validation_dir,fnames[errors[i]]))\n",
    "        plt.figure(figsize=[7,7])\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n",
    "        plt.imshow(original)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator, verbose=1)\n",
    "\n",
    "idx2label, errors, filenames = obtain_errors(test_generator, predictions)\n",
    "\n",
    "show_error(idx2label, errors, predictions, filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
