{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python.keras.applications.densenet import decode_predictions\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "## ENV VARS\n",
    "IMG_SIZE = 32\n",
    "SAVE_DIR = ''\n",
    "IMG_DIR = './scripts/output/*/*.jpg'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "#STATIC VARS\n",
    "dataset = []\n",
    "labels = []\n",
    "lb = LabelBinarizer()\n",
    "img_train = ''\n",
    "img_test = ''\n",
    "labels_train = ''\n",
    "labels_test = ''\n",
    "model = Sequential()\n",
    "classes = ''\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10.,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,\n",
    "    zoom_range=1.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "def preprocess():\n",
    "    dimensions = np.prod(img_train.shape[1:])\n",
    "    train_data = img_train.reshape(img_train.shape[0], dimensions).astype('float32')\n",
    "    test_data = img_train.reshape(img_test.shape[0], dimensions).astype('float32')\n",
    "    \n",
    "def generated_data(set, labels):\n",
    "    generator = data_gen.flow(\n",
    "    set,\n",
    "    labels, ##may need to be onehotenc\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "def import_imgs():\n",
    "    img_paths = []\n",
    "    path_list = os.listdir(IMG_DIR)\n",
    "    for i in path_list:\n",
    "        img_paths.append(os.path.join(IMG_DIR, i))\n",
    "    random.shuffle(img_paths)\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img_path == './scripts/output/sphinx/00000000.jpg': cv2.imshow(\"img\", img)\n",
    "        dataset.append(img)\n",
    "        \n",
    "        label = img_path.split('/')\n",
    "        labels.append(label[-2])\n",
    "    print(dataset)\n",
    "    temp_dataset = np.array(dataset, dtype='float32')/255.0\n",
    "    temp_labels = np.array(labels)\n",
    "    classes = np.unique(temp_labels)\n",
    "    (img_train, labels_train, img_test, labels_test) = train_test_split(temp_dataset, temp_labels, test_size=0.20)\n",
    "    \n",
    "def import_images():\n",
    "    paths = glob.glob(IMG_DIR)\n",
    "    \n",
    "\n",
    "def one_hot_enc(labels_train, labels_test):\n",
    "    #converts labels from int to vectors\n",
    "    #one hot encoding on labels is already done through transform, fit_transform finds all unique classes\n",
    "    labels_train = lb.fit_transform(labels_train)\n",
    "    labels_test = lb.transform(labels_test)\n",
    "    return labels_train, labels_test\n",
    "    \n",
    "def model_build():\n",
    "    #input is 3072=32x32x3\n",
    "    model.add(Dense(1024, input_shape=(3072,), activation='sigmoid'))\n",
    "    model.add(Dense(512, activation='sigmoid'))\n",
    "    model.add(Dense(len(lb.classes_), activation='softmax'))\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def print_results(model_fit):\n",
    "    N = np.arange(0, 30)\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(N, model_fit.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(N, model_fit.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(N, model_fit.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "    plt.plot(N, model_fit.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "    plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend()\n",
    "    \n",
    "def save_model():\n",
    "    model.save(model, save_format='h5')\n",
    "    f = open(SAVE_DIR, 'wb')\n",
    "    f.write(pickle.dumps(lb))\n",
    "    f.close()\n",
    "\n",
    "def train(with_gen:bool):\n",
    "    generator = generated_data(img_train, labels_train)\n",
    "    if with_gen:\n",
    "        history1 = model.fit(data_gen.flow(\n",
    "                                img_train,\n",
    "                                labels_train, ##may need to be onehotenc\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                target_size=(IMG_SIZE,IMG_SIZE),\n",
    "                                class_mode='categorical',\n",
    "                                shuffle=True\n",
    "                                ),\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(img_test, labels_test))\n",
    "    else:\n",
    "        model_fit = model.fit(img_train, labels_train,\n",
    "                              epochs=EPOCHS,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              validation_data=(img_test, labels_test))\n",
    "        \n",
    "def print_errors(img_generator, predictions):\n",
    "    fnames = img_generator.filenames\n",
    "    ground_truth = img_generator.classes\n",
    "    label2index = img_generator.class_indices\n",
    "    idx2label = list(label2index.keys())\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    errors = np.where(predicted_classes != ground_truth)[0]\n",
    "    print(\"Number of errors = {}/{}\".format(len(errors),img_generator.samples))\n",
    "    return idx2label, errors, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, momentum=0.7, decay=0.01/25)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(model.predict(img_test, batch_size=32))\n",
    "encoded_pred = decode_predictions(predictions)\n",
    "[test_loss, test_acc] = model.evaluate(img_test, labels_test)\n",
    "print(classification_report(labels_test.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))\n",
    "for pred in range(len(encoded_pred[0])):\n",
    "    print(encoded_pred[0][pred])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}